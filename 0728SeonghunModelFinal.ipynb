{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.autograd import Variable \n",
    "import argparse\n",
    "\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#from collections import Counter\n",
    "import torch.nn.utils as torch_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1000\n",
    "num_layers = 1\n",
    "#fName='helpdsk'\n",
    "#fName='Credit'\n",
    "fName='BPI12'\n",
    "#fName='BPI17'\n",
    "\n",
    "savePath = './Result/'\n",
    "modelName = 'RTPrediction_'\n",
    "modelVer = 'v1'\n",
    "\n",
    "if fName[:5]=='BPI12':\n",
    "    batch_size=1000\n",
    "    lr=0.0001\n",
    "elif fName[:5]=='BPI15':\n",
    "    batch_size=200\n",
    "    lr=0.0001\n",
    "elif fName[:5]=='BPI17':\n",
    "    batch_size=1000\n",
    "    lr=0.0001\n",
    "elif fName=='helpdsk':\n",
    "    batch_size=200\n",
    "    lr=0.0001\n",
    "elif fName=='Credit':\n",
    "    batch_size=1000\n",
    "    lr=0.001\n",
    "else:\n",
    "    batch_size=1000\n",
    "    lr=0.0005\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, batch_size, output_dim=1, num_layers=2):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.num_layers = num_layers\n",
    "        # define the LSTM layer\n",
    "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(self.hidden_dim, self.hidden_dim, self.num_layers, batch_first=True)\n",
    "        # define the output layer\n",
    "        self.bn = nn.BatchNorm1d(hidden_dim)\n",
    "        self.fc = nn.Linear(self.hidden_dim, output_dim)\n",
    "        \n",
    "    def init_hidden(self):\n",
    "        # initialize hidden states\n",
    "        return (torch.zeros(self.num_layers, self.batch_size, self.hidden_dim).type(dtype),\n",
    "                torch.zeros(self.num_layers, self.batch_size, self.hidden_dim).type(dtype))\n",
    "    \n",
    "    def forward(self, input):\n",
    "        input = input.type(dtype)\n",
    "        #print('input shape',input.shape)\n",
    "        lstm_out, self.hidden = self.lstm(input)\n",
    "        #print('lstm out', lstm_out.shape)\n",
    "        lstm_out = lstm_out.reshape(-1, lstm_out.shape[2])\n",
    "        #print('shaped',lstm_out.shape)\n",
    "        lstm_out = self.bn(lstm_out) # 배치정규화\n",
    "        #print('out bn',lstm_out.shape)\n",
    "        lstm_out = lstm_out.reshape(batch_size, int(lstm_out.shape[0]/batch_size), lstm_out.shape[1])\n",
    "        lstm_out, self.hidden = self.lstm2(lstm_out)  \n",
    "        lstm_out = lstm_out.reshape(-1, lstm_out.shape[2])\n",
    "        lstm_out = self.bn(lstm_out)\n",
    "        y_pred = self.fc(lstm_out)\n",
    "\n",
    "        y_pred = y_pred.reshape(self.batch_size, -1)\n",
    "        return y_pred[:,-1], self.hidden\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildOHE(index,n): # 원핫 인코딩\n",
    "    L=[0]*n\n",
    "    L[index]=1\n",
    "    return L\n",
    "\n",
    "def buildOHE2(index,arr): # 집약패턴 인코딩(이전 정보 반영)\n",
    "    arr[index]=1\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(name):\n",
    "\n",
    "    if name==\"BPI12\":\n",
    "        return _load_dataset_name(\"FinalData/bpi_12_w.csv\")\n",
    "    elif name==\"BPI15\":\n",
    "        return _load_dataset_name(\"FinalData/BPI15_1_Final_Nava.csv\")\n",
    "    elif name==\"BPI17\":\n",
    "        return _load_dataset_name(\"FinalData/BPI2017_M3000_Final_Nava.csv\")\n",
    "    elif name=='helpdsk':\n",
    "        return _load_dataset_name(\"FinalData/helpdesk_N.csv\")\n",
    "    elif name=='Credit':\n",
    "        return _load_dataset_name(\"FinalData/Credit_Final_Nava.csv\")\n",
    "    elif name=='Invoice':\n",
    "        return _load_dataset_name(\"FinalData/Invoice_Final_Nava.csv\")\n",
    "\n",
    "    \n",
    "def _load_dataset_name(fName):\n",
    "    dataframe = pd.read_csv(fName, header=0)\n",
    "    dataframe = dataframe.replace(r's+', 'empty', regex=True)\n",
    "    dataframe = dataframe.fillna(0)\n",
    "    dataset=dataframe.values\n",
    "    \n",
    "    print(dataframe[:20]) ########################################################3\n",
    "    \n",
    "    global gridNum\n",
    "    \n",
    "    values = []\n",
    "    for i in range(dataset.shape[1]):\n",
    "        values.append(len(np.unique(dataset[:, i])) )\n",
    "    print(values)\n",
    "\n",
    "    elems_per_fold = int(values[0] / 5)\n",
    "    datasetTR = dataset[dataset[:,0]<4*elems_per_fold]\n",
    "    datasetTS = dataset[dataset[:,0]>=4*elems_per_fold]       \n",
    "    print('Train : 0~',4*elems_per_fold,\" Test : \",4*elems_per_fold,'~',len(datasetTR))\n",
    "    \n",
    "    return generate_set(datasetTR, values, dataframe.dtypes), generate_set(datasetTS, values, dataframe.dtypes)    \n",
    "    \n",
    "    \n",
    "def generate_set(dataset, values, dfDtype):\n",
    "    data=[]\n",
    "    newdataset=[]\n",
    "    temptarget=[] \n",
    "    aggregation=[]\n",
    "    \n",
    "    actOccurCnt=[0]*(values[1]+1)\n",
    "    actOccurTime=[0]*(values[1]+1)\n",
    "    loopStartPoint=0\n",
    "\n",
    "    caseArr=[]\n",
    "    caseX=''\n",
    "        \n",
    "    #analyze first dataset line\n",
    "    caseID=dataset[0][0]\n",
    "    event=dataset[0][1]\n",
    "    \n",
    "    # 트레이스 시작 시간, 이전 이벤트 타임스탬프, 해당 이벤트 타임스탬프 날짜의 자정, 2,3번의 차이\n",
    "    starttime=datetime.fromtimestamp(time.mktime(time.strptime(dataset[0][2], \"%Y-%m-%d %H:%M:%S\")))\n",
    "    lastevtime=starttime\n",
    "    #t=time.strptime(dataset[0][2], \"%Y-%m-%d %H:%M:%S\")\n",
    "    midnight = starttime.replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "    timesincemidnight = (starttime - midnight).total_seconds()\n",
    "    \n",
    "    # 초기화 겸 첫 이벤트 값 처리\n",
    "    n=1\n",
    "    temptarget.append(starttime) ############# 이부분이 왜 starttime이 들어가는지 까먹었다\n",
    "    a=[0,0,timesincemidnight,starttime.weekday(),0] # 첫 이벤트는 경과시간이 0이므로 0으로 초기화\n",
    "    #[경과시간,이전이벤트로부터 경과시간, 자정으로부터경과시간, 요일, 반복실행으로부터경과시간]\n",
    "    idNum = int(dataset[0][1][1:])\n",
    "    aggregation=(buildOHE(idNum, values[1]+1)) ##0427##1\n",
    "    actOccurCnt[idNum]+=1 # 액티비티의 실행 횟수 카운트\n",
    "    actOccurTime[idNum]=starttime # 해당 액티비티의 첫 등장 시간 저장\n",
    "\n",
    "\n",
    "    field = 3\n",
    "    b=[]\n",
    "    for i in dataset[0][3:]:\n",
    "        if np.issubdtype(dfDtype[field], np.number):\n",
    "            a.append(i)\n",
    "        else:\n",
    "            b.extend(buildOHE(int(i[1:]), values[field]+1))\n",
    "        field+=1\n",
    "    \n",
    "    # 벡터에서 어느 파트까지가 스케일링이고 아이디고 인코딩인지 표시\n",
    "    vectorPoint=[len(a),len(aggregation),len(b)]\n",
    "    \n",
    "    a.extend(aggregation)\n",
    "    a.extend(b)\n",
    "    newdataset.append(a)\n",
    "\n",
    "        \n",
    "    for line in dataset[1:,:]:\n",
    "        case=line[0]\n",
    "        if case==caseID: #이전 이벤트랑 같은 트레이스 소속일 경우\n",
    "            #t = time.strptime(line[2], \"%Y-%m-%d %H:%M:%S\")\n",
    "            nowtime=datetime.fromtimestamp(time.mktime(time.strptime(line[2], \"%Y-%m-%d %H:%M:%S\")))\n",
    "            midnight = nowtime.replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "            temptarget.append(datetime.fromtimestamp(time.mktime(time.strptime(line[2], \"%Y-%m-%d %H:%M:%S\"))))  ##############\n",
    "            \n",
    "            a=[(nowtime- starttime).total_seconds()]\n",
    "            a.append((nowtime- lastevtime).total_seconds())\n",
    "            a.append((nowtime - midnight).total_seconds())   \n",
    "            a.append(nowtime.weekday())\n",
    "            \n",
    "            idNum = int(line[1][1:])\n",
    "            aggregation = (buildOHE2(idNum, aggregation)) ##0427##\n",
    "            \n",
    "            actOccurCnt[idNum]+=1 # 액티비티의 실행 횟수 카운트\n",
    "            if actOccurCnt[idNum]==1: # 해당 액티비티가 처음 등장했을 경우, 실행시간을 기록\n",
    "                actOccurTime[idNum]=nowtime \n",
    "            if actOccurCnt[idNum]>1: # 해당 액티비티가 반복 실행된 액티비티일 경우\n",
    "                if loopStartPoint==0: # 반복적 제어흐름의 첫 반복일 경우\n",
    "                    loopStartPoint = actOccurTime[idNum] # 반복적 제어흐름의 시작시간 저장\n",
    "                a.append((nowtime-loopStartPoint).total_seconds()) # 반복적 제어흐름 시작으로부터의 경과시간 계산 및 특징 추가\n",
    "            else:\n",
    "                loopStartPoint=0 # 반복적 제어흐름이 아닐경우 해당 변수 0으로 초기화\n",
    "                a.append(0) # 반복적 제어흐름으로부터의 경과시간 값으로 0 삽입\n",
    "            \n",
    "            field=3\n",
    "            b=[] # 스케일링 값은 a에 인코딩은 b에 그리고 나중에 a로 통합\n",
    "            for i in line[3:]:\n",
    "                if np.issubdtype(dfDtype[field], np.number):\n",
    "                    a.append(i)\n",
    "                else:\n",
    "                    b.extend(buildOHE(int(line[field][1:]), values[field]+1))\n",
    "                field+=1\n",
    "                \n",
    "            a.extend(aggregation)\n",
    "            a.extend(b)\n",
    "            newdataset.append(a)\n",
    "            n+=1\n",
    "            lastevtime = nowtime # 마지막 실행 이벤트 갱신\n",
    "            finishtime = nowtime\n",
    "            caseX=line[0]\n",
    "                \n",
    "            \n",
    "        else: # 새로운 트레이스가 시작될때\n",
    "            caseID=case\n",
    "            for i in range(1,len(newdataset)):\n",
    "                data.append(newdataset[:i+1])\n",
    "                caseArr.append(caseX)\n",
    "                \n",
    "            actOccurCnt=[0]*(values[1]+1)\n",
    "            actOccurTime=[0]*(values[1]+1)\n",
    "            newdataset=[]\n",
    "            starttime = datetime.fromtimestamp(time.mktime(time.strptime(line[2], \"%Y-%m-%d %H:%M:%S\")))\n",
    "            \n",
    "            #t = time.strptime(line[2], \"%Y-%m-%d %H:%M:%S\")\n",
    "            midnight = starttime.replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "            timesincemidnight = (starttime - midnight).total_seconds()\n",
    "            \n",
    "            a=[0,0,timesincemidnight, starttime.weekday(),0]\n",
    "            #[경과시간,이전이벤트로부터 경과시간, 자정으로부터경과시간, 요일, 반복실행으로부터경과시간]\n",
    "            idNum = int(line[1][1:])\n",
    "            aggregation=(buildOHE(int(line[1][1:]), values[1]+1))\n",
    "            \n",
    "            actOccurCnt[idNum]+=1 # 액티비티의 실행 횟수 카운트\n",
    "            actOccurTime[idNum]=starttime # 해당 액티비티의 첫 등장 시간 저장\n",
    "\n",
    "\n",
    "            field=3\n",
    "            b=[]\n",
    "            for i in line[3:]:\n",
    "                if np.issubdtype(dfDtype[field], np.number):\n",
    "                    a.append(i)\n",
    "                else:\n",
    "                    b.extend(buildOHE(int(line[field][1:]), values[field]+1))\n",
    "                field+=1\n",
    "            a.extend(aggregation)\n",
    "            a.extend(b)\n",
    "            newdataset.append(a)\n",
    "                \n",
    "            # 그동안 종료시간을 담아오다가 해당 트레이스 길이만큼 거꾸로 가면서 잔여시간 계산\n",
    "            for i in range(n):\n",
    "                temptarget[-(i+1)]=(finishtime-temptarget[-(i+1)]).total_seconds() \n",
    "            temptarget.pop() #마지막 종료된 상태는 예측에서 제외\n",
    "            temptarget.append(starttime)\n",
    "            \n",
    "            lastevtime = starttime\n",
    "            finishtime = starttime\n",
    "            n = 1\n",
    "        \n",
    "    # 마지막 트레이스 처리파트\n",
    "    for i in range(1,len(newdataset)):\n",
    "        data.append(newdataset[:i+1])\n",
    "        caseArr.append(caseX) ###0504\n",
    "    \n",
    "    for i in range(n):\n",
    "        temptarget[-(i + 1)] = (finishtime - temptarget[-(i + 1)]).total_seconds()\n",
    "    temptarget.pop()\n",
    "\n",
    "\n",
    "    print(len(data))\n",
    "    print(\"Generated dataset with n_samples:\", len(temptarget))\n",
    "    assert(len(temptarget)== len(data))\n",
    "    print(vectorPoint)\n",
    "    return data, temptarget, vectorPoint, caseArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    CaseID Activity    CompleteTimestamp\n",
      "0        1       a1  2011-10-01 19:45:00\n",
      "1        1       a2  2011-10-01 20:17:00\n",
      "2        1       a2   2011-10-09 0:32:00\n",
      "3        1       a2  2011-10-10 19:33:00\n",
      "4        1       a3  2011-10-13 18:37:00\n",
      "5        2       a1  2011-10-01 19:43:00\n",
      "6        2       a1  2011-10-01 22:35:00\n",
      "7        2       a2  2011-10-01 22:36:00\n",
      "8        2       a2   2011-10-04 0:56:00\n",
      "9        2       a2   2011-10-04 0:57:00\n",
      "10       2       a2  2011-10-10 18:14:00\n",
      "11       2       a3  2011-10-10 19:30:00\n",
      "12       2       a3  2011-10-10 22:14:00\n",
      "13       2       a3  2011-10-10 22:17:00\n",
      "14       3       a1  2011-10-01 19:35:00\n",
      "15       3       a1  2011-10-03 19:21:00\n",
      "16       3       a1  2011-10-03 21:32:00\n",
      "17       3       a1  2011-10-03 21:40:00\n",
      "18       3       a2  2011-10-03 21:44:00\n",
      "19       3       a2   2011-10-11 0:47:00\n",
      "[9658, 6, 48282]\n",
      "Train : 0~ 7724  Test :  7724 ~ 59126\n",
      "51403\n",
      "Generated dataset with n_samples: 51403\n",
      "[5, 7, 0]\n",
      "11352\n",
      "Generated dataset with n_samples: 11352\n",
      "[5, 7, 0]\n"
     ]
    }
   ],
   "source": [
    "(train_x_origin, train_y_origin, vectorP, train_case),(test_x_origin, test_y_origin, vectorP, test_case)= load_dataset(fName)\n",
    "#[스케일링파트, 아이디 인코딩 파트, 기타 속성 인코딩 파트] 각 파트의 길이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 70980.0, 5, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       " [10320.0, 10320.0, 81300.0, 5, 10320.0, 0, 1, 0, 0, 0, 0, 0],\n",
       " [10380.0, 60.0, 81360.0, 5, 0, 0, 1, 1, 0, 0, 0, 0],\n",
       " [191580.0, 181200.0, 3360.0, 1, 181200.0, 0, 1, 1, 0, 0, 0, 0],\n",
       " [191640.0, 60.0, 3420.0, 1, 181260.0, 0, 1, 1, 0, 0, 0, 0],\n",
       " [772260.0, 580620.0, 65640.0, 0, 761880.0, 0, 1, 1, 0, 0, 0, 0],\n",
       " [776820.0, 4560.0, 70200.0, 0, 0, 0, 1, 1, 1, 0, 0, 0]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_origin[9]\n",
    "#경과시간, 이전이벤트로부터 경과시간, 자정으로부터 경과시간, 요일, 반복적제어흐름으로부터의 경과시간, [아이디 인코딩] , 기타 리소스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vecToStr(vec):\n",
    "    re=''\n",
    "    for x in vec:\n",
    "        re += str(x)\n",
    "    return re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#집약패턴에 따른 평균 잔여시간 계산 파트\n",
    "\n",
    "CRTdic={}\n",
    "CRTvalue={}\n",
    "totalRT=[] #모든 인스턴스(부분포함)의 잔여시간을 담을 리스트\n",
    "\n",
    "preLen=99\n",
    "for x,y in zip(train_x_origin,train_y_origin):\n",
    "    if preLen>len(x): #인스턴스의 첫 이벤트일 경우\n",
    "        cid = vecToStr(x[0][vectorP[0]:vectorP[0]+vectorP[1]])\n",
    "        try:\n",
    "            CRTdic[cid][0]+=y\n",
    "            CRTdic[cid][1]+=1          \n",
    "        except:\n",
    "            CRTdic[cid]=[y,1] #총 잔여시간, 개수\n",
    "            \n",
    "    cid = vecToStr(x[-1][vectorP[0]:vectorP[0]+vectorP[1]])\n",
    "    try:\n",
    "        CRTdic[cid][0]+=y\n",
    "        CRTdic[cid][1]+=1  \n",
    "    except:\n",
    "        CRTdic[cid]=[y,1] #총 잔여시간, 개수\n",
    "    \n",
    "    preLen=len(x)\n",
    "    totalRT.append(y)\n",
    "\n",
    "#잔여시간에 대한 최대 최소 및 사분위수 값 계산\n",
    "totalQ = [np.quantile(totalRT,0.0),np.quantile(totalRT,0.25),np.quantile(totalRT,0.50),\n",
    "                 np.quantile(totalRT,0.75),np.quantile(totalRT,1.0),np.mean(totalRT)]\n",
    "#Min-Max 정규화 적용\n",
    "for x in CRTdic:\n",
    "    CRTvalue[x]=(totalQ[4]-int(CRTdic[x][0]/CRTdic[x][1]))/(totalQ[4]-totalQ[0])\n",
    "#print(CRTvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 액티비티별 정규화 파트\n",
    "# 액티비티는 업무수행의 기본 단위로 액티비티별로 다른 속성과 인과관계를 가지므로 개별 정규화 수행\n",
    "idSpoint=vectorP[0]\n",
    "idEpoint=vectorP[1]+vectorP[0]\n",
    "\n",
    "tmpArr = [[] for i in range(vectorP[0])]\n",
    "tmpArrY = [[] for i in range(vectorP[0])]\n",
    "\n",
    "for ep in range(vectorP[0]):# 벡터 한칸씩 처리\n",
    "    saveArr=[[] for i in range(vectorP[1])]\n",
    "    for x in train_x_origin:  # 아이디별로 값 수집\n",
    "        saveArr[x[-1][idSpoint:idEpoint].index(1)].append(x[-1][ep])\n",
    "        saveArr[0].append(x[-1][ep])\n",
    "            \n",
    "    pointArr=[[]]\n",
    "    for x in saveArr[1:]: # 최대최소 및 사분위 값 계산\n",
    "        try:\n",
    "            pointArr.append([np.quantile(x,0.0),np.quantile(x,0.25),np.quantile(x,0.50),np.quantile(x,0.75),np.quantile(x,1.0),np.mean(x), np.std(x)])\n",
    "        except: # 처음 등장하는 이벤트의 경우 전체에대한 최대최소 값으로 정규화 수행\n",
    "            pointArr.append([np.quantile(saveArr[0],0.0),np.quantile(saveArr[0],0.25),np.quantile(saveArr[0],0.50),np.quantile(saveArr[0],0.75),np.quantile(saveArr[0],1.0),np.mean(saveArr[0]), np.std(saveArr[0])])        \n",
    "        \n",
    "\n",
    "    for xi, x in enumerate(train_x_origin):\n",
    "        for xxi ,xx in enumerate(x): # 이벤트 하나씩 처리\n",
    "            idNum=xx[idSpoint:idEpoint].index(1)\n",
    "            if not pointArr[idNum][4]==pointArr[idNum][0]: # 모든 값이 0 으로 되어있을 경우 또는 같은 값으로 이루어질경우\n",
    "                tmpArr[ep].append((xx[ep]-pointArr[idNum][0])/(pointArr[idNum][4]-pointArr[idNum][0]))\n",
    "            else:\n",
    "                tmpArr[ep].append(0)\n",
    "                \n",
    "    for xi, x in enumerate(test_x_origin):\n",
    "        for xxi ,xx in enumerate(x): # 이벤트 하나씩 처리\n",
    "            idNum=xx[idSpoint:idEpoint].index(1)\n",
    "            if not pointArr[idNum][4]==pointArr[idNum][0]: # 모든 값이 0 으로 되어있을 경우 또는 같은 값으로 이루어질경우\n",
    "                tmpArrY[ep].append((xx[ep]-pointArr[idNum][0])/(pointArr[idNum][4]-pointArr[idNum][0]))\n",
    "            else:\n",
    "                tmpArrY[ep].append(0)\n",
    "                \n",
    "i=0\n",
    "for xi, x in enumerate(train_x_origin):\n",
    "    for xxi, xx in enumerate(x):\n",
    "        tmp=[]\n",
    "        for j in range(len(tmpArr)):\n",
    "            tmp.append(tmpArr[j][i])\n",
    "        train_x_origin[xi][xxi][:vectorP[0]]=tmp\n",
    "        i+=1\n",
    "i=0       \n",
    "for xi, x in enumerate(test_x_origin):\n",
    "    for xxi, xx in enumerate(x):\n",
    "        tmp=[]\n",
    "        for j in range(len(tmpArrY)):\n",
    "            tmp.append(tmpArrY[j][i])\n",
    "        test_x_origin[xi][xxi][:vectorP[0]]=tmp\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 목표값의 단위를 day로 변경\n",
    "# 타 논문과 성능 비교를 위해 동일한 단위로 변경\n",
    "train_y_origin = [y1/(3600*24) for y1 in train_y_origin]\n",
    "test_y_origin = [y1/(3600*24) for y1 in test_y_origin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력벡터 패딩 (공백을 전방에 배치)\n",
    "maxTraceLen = len(max(train_x_origin,key=len))\n",
    "dicLen = len(train_x_origin[0][0])\n",
    "dumyPadding = [0]*dicLen\n",
    "\n",
    "# 실제값과 패딩값의 구분 마스크\n",
    "train_mask=[]\n",
    "test_mask=[]\n",
    "\n",
    "changedArr = train_x_origin\n",
    "for i in range(len(changedArr)):\n",
    "    if len(changedArr[i]) < maxTraceLen:\n",
    "        train_mask.append(len(changedArr[i]))\n",
    "        for x in range(maxTraceLen-len(changedArr[i])):\n",
    "            changedArr[i].insert(0,dumyPadding)\n",
    "    elif len(changedArr[i]) > maxTraceLen:\n",
    "        train_mask.append(maxTraceLen)\n",
    "        changedArr[i] = changedArr[i][:maxTraceLen]\n",
    "    else:\n",
    "        train_mask.append(maxTraceLen)       \n",
    "train_x_origin = changedArr\n",
    "\n",
    "changedArr = test_x_origin\n",
    "for i in range(len(changedArr)):\n",
    "    if len(changedArr[i]) < maxTraceLen:\n",
    "        test_mask.append(len(changedArr[i]))\n",
    "        for x in range(maxTraceLen-len(changedArr[i])):\n",
    "            changedArr[i].insert(0,dumyPadding)\n",
    "    elif len(changedArr[i]) > maxTraceLen:\n",
    "        test_mask.append(maxTraceLen)\n",
    "        changedArr[i] = changedArr[i][:maxTraceLen]\n",
    "    else:\n",
    "        test_mask.append(maxTraceLen)\n",
    "test_x_origin = changedArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x=train_x_origin\n",
    "train_y=train_y_origin\n",
    "\n",
    "test_x=test_x_origin\n",
    "test_y=test_y_origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습데이터셋의 1/8을 검증셋으로 사용 (총 학습70, 검증10, 테스트20)\n",
    "Valkey = int(len(train_x)/10*8)+1\n",
    "valid_x = train_x[Valkey:]\n",
    "valid_y = train_y[Valkey:]\n",
    "train_x = train_x[:Valkey]\n",
    "train_y = train_y[:Valkey]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 파라미터 설정 및 모델생성\n",
    "\n",
    "is_cuda = torch.cuda.is_available()\n",
    "dict_size = len(train_x[0][0])\n",
    "hidden_dim = vectorP[1]*2\n",
    "#print(dict_size)\n",
    "#print(hidden_dim)\n",
    "\n",
    "model = LSTM(dict_size, hidden_dim, batch_size=batch_size, output_dim=1, num_layers=num_layers)\n",
    "if is_cuda : model = model.cuda()\n",
    "dtype = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.float\n",
    "\n",
    "criterion = nn.L1Loss() # MAE\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1/1000]]\ttraining :  12.207\t // validation :  11.4577\t**** 1 ****\n",
      "[[2/1000]]\ttraining :  11.8428\t // validation :  11.5041\t\n",
      "[[3/1000]]\ttraining :  11.5115\t // validation :  11.435\t**** 3 ****\n",
      "[[4/1000]]\ttraining :  11.2076\t // validation :  11.2463\t**** 4 ****\n",
      "[[5/1000]]\ttraining :  10.8719\t // validation :  10.9478\t**** 5 ****\n",
      "[[6/1000]]\ttraining :  10.5279\t // validation :  10.6189\t**** 6 ****\n",
      "[[7/1000]]\ttraining :  10.2758\t // validation :  10.3496\t**** 7 ****\n",
      "[[8/1000]]\ttraining :  10.0841\t // validation :  10.1207\t**** 8 ****\n",
      "[[9/1000]]\ttraining :  9.924\t // validation :  9.9303\t**** 9 ****\n",
      "[[10/1000]]\ttraining :  9.7777\t // validation :  9.7655\t**** 10 ****\n",
      "[[11/1000]]\ttraining :  9.6322\t // validation :  9.6142\t**** 11 ****\n",
      "[[12/1000]]\ttraining :  9.4769\t // validation :  9.4923\t**** 12 ****\n",
      "[[13/1000]]\ttraining :  9.3415\t // validation :  9.4038\t**** 13 ****\n",
      "[[14/1000]]\ttraining :  9.2376\t // validation :  9.3251\t**** 14 ****\n",
      "[[15/1000]]\ttraining :  9.1478\t // validation :  9.2578\t**** 15 ****\n",
      "[[16/1000]]\ttraining :  9.0657\t // validation :  9.2007\t**** 16 ****\n",
      "[[17/1000]]\ttraining :  8.9899\t // validation :  9.1509\t**** 17 ****\n",
      "[[18/1000]]\ttraining :  8.9187\t // validation :  9.1079\t**** 18 ****\n",
      "[[19/1000]]\ttraining :  8.8516\t // validation :  9.071\t**** 19 ****\n",
      "[[20/1000]]\ttraining :  8.7884\t // validation :  9.0399\t**** 20 ****\n",
      "[[21/1000]]\ttraining :  8.7282\t // validation :  9.0171\t**** 21 ****\n",
      "[[22/1000]]\ttraining :  8.6708\t // validation :  8.9996\t**** 22 ****\n",
      "[[23/1000]]\ttraining :  8.6163\t // validation :  8.9851\t**** 23 ****\n",
      "[[24/1000]]\ttraining :  8.5649\t // validation :  8.9737\t**** 24 ****\n",
      "[[25/1000]]\ttraining :  8.5168\t // validation :  8.9663\t**** 25 ****\n",
      "[[26/1000]]\ttraining :  8.4722\t // validation :  8.9635\t**** 26 ****\n",
      "[[27/1000]]\ttraining :  8.4304\t // validation :  8.9626\t**** 27 ****\n",
      "[[28/1000]]\ttraining :  8.3918\t // validation :  8.9673\t\n",
      "[[29/1000]]\ttraining :  8.3561\t // validation :  8.9723\t\n",
      "[[30/1000]]\ttraining :  8.3228\t // validation :  8.9827\t\n",
      "[[31/1000]]\ttraining :  8.2917\t // validation :  8.9908\t\n",
      "[[32/1000]]\ttraining :  8.2626\t // validation :  8.9976\t\n",
      "[[33/1000]]\ttraining :  8.2355\t // validation :  9.0092\t\n",
      "[[34/1000]]\ttraining :  8.2105\t // validation :  9.0203\t\n",
      "[[35/1000]]\ttraining :  8.1878\t // validation :  9.0336\t\n",
      "[[36/1000]]\ttraining :  8.1671\t // validation :  9.0457\t\n",
      "[[37/1000]]\ttraining :  8.1484\t // validation :  9.057\t\n",
      "[[38/1000]]\ttraining :  8.1317\t // validation :  9.0652\t\n",
      "[[39/1000]]\ttraining :  8.1159\t // validation :  9.078\t\n",
      "[[40/1000]]\ttraining :  8.1012\t // validation :  9.0887\t\n",
      "[[41/1000]]\ttraining :  8.0878\t // validation :  9.0991\t\n",
      "[[42/1000]]\ttraining :  8.0753\t // validation :  9.1036\t\n",
      "[[43/1000]]\ttraining :  8.0639\t // validation :  9.1101\t\n",
      "[[44/1000]]\ttraining :  8.0532\t // validation :  9.1138\t\n",
      "[[45/1000]]\ttraining :  8.043\t // validation :  9.119\t\n",
      "[[46/1000]]\ttraining :  8.0336\t // validation :  9.1263\t\n",
      "[[47/1000]]\ttraining :  8.0248\t // validation :  9.1331\t\n",
      "[[48/1000]]\ttraining :  8.0163\t // validation :  9.1366\t\n",
      "[[49/1000]]\ttraining :  8.0085\t // validation :  9.1421\t\n",
      "[[50/1000]]\ttraining :  8.001\t // validation :  9.1473\t\n",
      "[[51/1000]]\ttraining :  7.994\t // validation :  9.1529\t\n",
      "[[52/1000]]\ttraining :  7.9872\t // validation :  9.1546\t\n",
      "[[53/1000]]\ttraining :  7.981\t // validation :  9.157\t\n",
      "[[54/1000]]\ttraining :  7.9748\t // validation :  9.1598\t\n",
      "[[55/1000]]\ttraining :  7.969\t // validation :  9.1651\t\n",
      "[[56/1000]]\ttraining :  7.9632\t // validation :  9.1731\t\n",
      "[[57/1000]]\ttraining :  7.9576\t // validation :  9.1744\t\n",
      "[[58/1000]]\ttraining :  7.9522\t // validation :  9.1813\t\n",
      "[[59/1000]]\ttraining :  7.9467\t // validation :  9.189\t\n",
      "[[60/1000]]\ttraining :  7.9415\t // validation :  9.191\t\n",
      "[[61/1000]]\ttraining :  7.9364\t // validation :  9.2025\t\n",
      "[[62/1000]]\ttraining :  7.9313\t // validation :  9.2102\t\n",
      "[[63/1000]]\ttraining :  7.9264\t // validation :  9.2175\t\n",
      "[[64/1000]]\ttraining :  7.9214\t // validation :  9.2309\t\n",
      "[[65/1000]]\ttraining :  7.9163\t // validation :  9.2368\t\n",
      "[[66/1000]]\ttraining :  7.9115\t // validation :  9.2451\t\n",
      "[[67/1000]]\ttraining :  7.9068\t // validation :  9.2514\t\n",
      "[[68/1000]]\ttraining :  7.9018\t // validation :  9.2585\t\n",
      "[[69/1000]]\ttraining :  7.8973\t // validation :  9.2659\t\n",
      "[[70/1000]]\ttraining :  7.8926\t // validation :  9.27\t\n",
      "[[71/1000]]\ttraining :  7.8879\t // validation :  9.2747\t\n",
      "[[72/1000]]\ttraining :  7.8836\t // validation :  9.2798\t\n",
      "[[73/1000]]\ttraining :  7.879\t // validation :  9.2922\t\n",
      "[[74/1000]]\ttraining :  7.8743\t // validation :  9.297\t\n",
      "[[75/1000]]\ttraining :  7.87\t // validation :  9.3\t\n",
      "[[76/1000]]\ttraining :  7.8656\t // validation :  9.3052\t\n",
      "[[77/1000]]\ttraining :  7.861\t // validation :  9.3069\t\n",
      "[[78/1000]]\ttraining :  7.8567\t // validation :  9.3153\t\n",
      "[[79/1000]]\ttraining :  7.8524\t // validation :  9.3177\t\n",
      "[[80/1000]]\ttraining :  7.8483\t // validation :  9.3235\t\n",
      "[[81/1000]]\ttraining :  7.8441\t // validation :  9.3226\t\n",
      "[[82/1000]]\ttraining :  7.8403\t // validation :  9.3248\t\n",
      "[[83/1000]]\ttraining :  7.8364\t // validation :  9.3284\t\n",
      "[[84/1000]]\ttraining :  7.8328\t // validation :  9.3334\t\n",
      "[[85/1000]]\ttraining :  7.8292\t // validation :  9.3325\t\n",
      "[[86/1000]]\ttraining :  7.8256\t // validation :  9.3328\t\n",
      "[[87/1000]]\ttraining :  7.8221\t // validation :  9.3381\t\n",
      "[[88/1000]]\ttraining :  7.8188\t // validation :  9.339\t\n",
      "[[89/1000]]\ttraining :  7.8156\t // validation :  9.3388\t\n",
      "[[90/1000]]\ttraining :  7.8124\t // validation :  9.3448\t\n",
      "[[91/1000]]\ttraining :  7.8091\t // validation :  9.3463\t\n",
      "[[92/1000]]\ttraining :  7.8062\t // validation :  9.3489\t\n",
      "[[93/1000]]\ttraining :  7.8033\t // validation :  9.3519\t\n",
      "[[94/1000]]\ttraining :  7.8002\t // validation :  9.3549\t\n",
      "[[95/1000]]\ttraining :  7.7973\t // validation :  9.3576\t\n",
      "[[96/1000]]\ttraining :  7.7947\t // validation :  9.3614\t\n",
      "[[97/1000]]\ttraining :  7.792\t // validation :  9.364\t\n",
      "[[98/1000]]\ttraining :  7.7893\t // validation :  9.3657\t\n",
      "[[99/1000]]\ttraining :  7.7866\t // validation :  9.3731\t\n",
      "[[100/1000]]\ttraining :  7.784\t // validation :  9.3735\t\n",
      "[[101/1000]]\ttraining :  7.7817\t // validation :  9.3769\t\n",
      "[[102/1000]]\ttraining :  7.7794\t // validation :  9.3838\t\n",
      "[[103/1000]]\ttraining :  7.7768\t // validation :  9.388\t\n",
      "[[104/1000]]\ttraining :  7.7749\t // validation :  9.3813\t\n",
      "[[105/1000]]\ttraining :  7.7726\t // validation :  9.3881\t\n",
      "[[106/1000]]\ttraining :  7.7703\t // validation :  9.3935\t\n",
      "[[107/1000]]\ttraining :  7.7681\t // validation :  9.399\t\n",
      "[[108/1000]]\ttraining :  7.7663\t // validation :  9.4\t\n",
      "[[109/1000]]\ttraining :  7.7643\t // validation :  9.4037\t\n",
      "[[110/1000]]\ttraining :  7.7621\t // validation :  9.4017\t\n",
      "[[111/1000]]\ttraining :  7.7597\t // validation :  9.4007\t\n",
      "[[112/1000]]\ttraining :  7.7579\t // validation :  9.4057\t\n",
      "[[113/1000]]\ttraining :  7.7561\t // validation :  9.3975\t\n",
      "[[114/1000]]\ttraining :  7.7543\t // validation :  9.403\t\n",
      "[[115/1000]]\ttraining :  7.7525\t // validation :  9.4006\t\n",
      "[[116/1000]]\ttraining :  7.7505\t // validation :  9.3938\t\n",
      "[[117/1000]]\ttraining :  7.7487\t // validation :  9.3953\t\n",
      "[[118/1000]]\ttraining :  7.7467\t // validation :  9.3882\t\n",
      "[[119/1000]]\ttraining :  7.7446\t // validation :  9.3865\t\n",
      "[[120/1000]]\ttraining :  7.7428\t // validation :  9.3809\t\n",
      "[[121/1000]]\ttraining :  7.7412\t // validation :  9.3791\t\n",
      "[[122/1000]]\ttraining :  7.7396\t // validation :  9.3705\t\n",
      "[[123/1000]]\ttraining :  7.7377\t // validation :  9.3726\t\n",
      "[[124/1000]]\ttraining :  7.7355\t // validation :  9.3696\t\n",
      "[[125/1000]]\ttraining :  7.7341\t // validation :  9.3666\t\n",
      "[[126/1000]]\ttraining :  7.7323\t // validation :  9.3617\t\n",
      "[[127/1000]]\ttraining :  7.7311\t // validation :  9.3577\t\n",
      "[[128/1000]]\ttraining :  7.729\t // validation :  9.3532\t\n",
      "[[129/1000]]\ttraining :  7.7276\t // validation :  9.3498\t\n",
      "[[130/1000]]\ttraining :  7.7259\t // validation :  9.3439\t\n",
      "[[131/1000]]\ttraining :  7.7243\t // validation :  9.348\t\n",
      "[[132/1000]]\ttraining :  7.7229\t // validation :  9.34\t\n",
      "[[133/1000]]\ttraining :  7.7211\t // validation :  9.3412\t\n",
      "[[134/1000]]\ttraining :  7.7195\t // validation :  9.3406\t\n",
      "[[135/1000]]\ttraining :  7.7179\t // validation :  9.3342\t\n",
      "[[136/1000]]\ttraining :  7.7163\t // validation :  9.3386\t\n",
      "[[137/1000]]\ttraining :  7.7148\t // validation :  9.3327\t\n",
      "[[138/1000]]\ttraining :  7.7136\t // validation :  9.3271\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[139/1000]]\ttraining :  7.7121\t // validation :  9.3237\t\n",
      "[[140/1000]]\ttraining :  7.7107\t // validation :  9.3218\t\n",
      "[[141/1000]]\ttraining :  7.7093\t // validation :  9.3201\t\n",
      "[[142/1000]]\ttraining :  7.7079\t // validation :  9.3175\t\n",
      "[[143/1000]]\ttraining :  7.7062\t // validation :  9.316\t\n",
      "[[144/1000]]\ttraining :  7.7049\t // validation :  9.3189\t\n",
      "[[145/1000]]\ttraining :  7.7035\t // validation :  9.3048\t\n",
      "[[146/1000]]\ttraining :  7.702\t // validation :  9.3079\t\n",
      "[[147/1000]]\ttraining :  7.7006\t // validation :  9.307\t\n",
      "[[148/1000]]\ttraining :  7.6991\t // validation :  9.307\t\n",
      "[[149/1000]]\ttraining :  7.6975\t // validation :  9.2959\t\n",
      "[[150/1000]]\ttraining :  7.6962\t // validation :  9.2958\t\n",
      "[[151/1000]]\ttraining :  7.6948\t // validation :  9.2941\t\n",
      "[[152/1000]]\ttraining :  7.6933\t // validation :  9.2955\t\n",
      "[[153/1000]]\ttraining :  7.6919\t // validation :  9.2898\t\n",
      "[[154/1000]]\ttraining :  7.6905\t // validation :  9.2854\t\n",
      "[[155/1000]]\ttraining :  7.6893\t // validation :  9.2854\t\n",
      "[[156/1000]]\ttraining :  7.6877\t // validation :  9.2891\t\n",
      "[[157/1000]]\ttraining :  7.6865\t // validation :  9.2858\t\n",
      "[[158/1000]]\ttraining :  7.6852\t // validation :  9.2706\t\n",
      "[[159/1000]]\ttraining :  7.6838\t // validation :  9.27\t\n",
      "[[160/1000]]\ttraining :  7.6826\t // validation :  9.2695\t\n",
      "[[161/1000]]\ttraining :  7.6811\t // validation :  9.2699\t\n",
      "[[162/1000]]\ttraining :  7.6798\t // validation :  9.2623\t\n",
      "[[163/1000]]\ttraining :  7.6785\t // validation :  9.2603\t\n",
      "[[164/1000]]\ttraining :  7.6772\t // validation :  9.2589\t\n",
      "[[165/1000]]\ttraining :  7.6757\t // validation :  9.2539\t\n",
      "[[166/1000]]\ttraining :  7.6744\t // validation :  9.256\t\n",
      "[[167/1000]]\ttraining :  7.6731\t // validation :  9.247\t\n",
      "[[168/1000]]\ttraining :  7.6718\t // validation :  9.2457\t\n",
      "[[169/1000]]\ttraining :  7.6701\t // validation :  9.2447\t\n",
      "[[170/1000]]\ttraining :  7.6692\t // validation :  9.2403\t\n",
      "[[171/1000]]\ttraining :  7.6678\t // validation :  9.2401\t\n",
      "[[172/1000]]\ttraining :  7.6668\t // validation :  9.2324\t\n",
      "[[173/1000]]\ttraining :  7.6655\t // validation :  9.2339\t\n",
      "[[174/1000]]\ttraining :  7.6642\t // validation :  9.2317\t\n",
      "[[175/1000]]\ttraining :  7.6632\t // validation :  9.234\t\n",
      "[[176/1000]]\ttraining :  7.6617\t // validation :  9.2287\t\n",
      "[[177/1000]]\ttraining :  7.6606\t // validation :  9.2234\t\n",
      "[[178/1000]]\ttraining :  7.6591\t // validation :  9.2251\t\n",
      "[[179/1000]]\ttraining :  7.6582\t // validation :  9.2274\t\n",
      "[[180/1000]]\ttraining :  7.6569\t // validation :  9.221\t\n",
      "[[181/1000]]\ttraining :  7.6555\t // validation :  9.2195\t\n",
      "[[182/1000]]\ttraining :  7.6543\t // validation :  9.2218\t\n",
      "[[183/1000]]\ttraining :  7.653\t // validation :  9.2214\t\n",
      "[[184/1000]]\ttraining :  7.6518\t // validation :  9.2204\t\n",
      "[[185/1000]]\ttraining :  7.6506\t // validation :  9.2169\t\n",
      "[[186/1000]]\ttraining :  7.6494\t // validation :  9.2186\t\n",
      "[[187/1000]]\ttraining :  7.6485\t // validation :  9.22\t\n",
      "[[188/1000]]\ttraining :  7.6472\t // validation :  9.2172\t\n",
      "[[189/1000]]\ttraining :  7.6462\t // validation :  9.216\t\n",
      "[[190/1000]]\ttraining :  7.6454\t // validation :  9.2149\t\n",
      "[[191/1000]]\ttraining :  7.644\t // validation :  9.2138\t\n",
      "[[192/1000]]\ttraining :  7.643\t // validation :  9.2128\t\n",
      "[[193/1000]]\ttraining :  7.6417\t // validation :  9.2166\t\n",
      "[[194/1000]]\ttraining :  7.6406\t // validation :  9.2134\t\n",
      "[[195/1000]]\ttraining :  7.6395\t // validation :  9.2096\t\n",
      "[[196/1000]]\ttraining :  7.6385\t // validation :  9.2078\t\n",
      "[[197/1000]]\ttraining :  7.6375\t // validation :  9.2068\t\n",
      "[[198/1000]]\ttraining :  7.6358\t // validation :  9.2093\t\n",
      "[[199/1000]]\ttraining :  7.6348\t // validation :  9.208\t\n",
      "[[200/1000]]\ttraining :  7.6334\t // validation :  9.2013\t\n",
      "[[201/1000]]\ttraining :  7.6321\t // validation :  9.2039\t\n",
      "[[202/1000]]\ttraining :  7.6313\t // validation :  9.1997\t\n",
      "[[203/1000]]\ttraining :  7.6307\t // validation :  9.1951\t\n",
      "[[204/1000]]\ttraining :  7.6298\t // validation :  9.1931\t\n",
      "[[205/1000]]\ttraining :  7.6283\t // validation :  9.1931\t\n",
      "[[206/1000]]\ttraining :  7.6272\t // validation :  9.1899\t\n",
      "[[207/1000]]\ttraining :  7.6262\t // validation :  9.1923\t\n",
      "[[208/1000]]\ttraining :  7.6251\t // validation :  9.1873\t\n",
      "[[209/1000]]\ttraining :  7.6238\t // validation :  9.1805\t\n",
      "[[210/1000]]\ttraining :  7.623\t // validation :  9.1772\t\n",
      "[[211/1000]]\ttraining :  7.622\t // validation :  9.174\t\n",
      "[[212/1000]]\ttraining :  7.621\t // validation :  9.1752\t\n",
      "[[213/1000]]\ttraining :  7.62\t // validation :  9.1732\t\n",
      "[[214/1000]]\ttraining :  7.6187\t // validation :  9.1699\t\n",
      "[[215/1000]]\ttraining :  7.6175\t // validation :  9.1678\t\n",
      "[[216/1000]]\ttraining :  7.6169\t // validation :  9.1647\t\n",
      "[[217/1000]]\ttraining :  7.6157\t // validation :  9.1568\t\n",
      "[[218/1000]]\ttraining :  7.6147\t // validation :  9.1595\t\n",
      "[[219/1000]]\ttraining :  7.6141\t // validation :  9.1582\t\n",
      "[[220/1000]]\ttraining :  7.6124\t // validation :  9.1531\t\n",
      "[[221/1000]]\ttraining :  7.6117\t // validation :  9.1492\t\n",
      "[[222/1000]]\ttraining :  7.6107\t // validation :  9.147\t\n",
      "[[223/1000]]\ttraining :  7.6098\t // validation :  9.1457\t\n",
      "[[224/1000]]\ttraining :  7.6088\t // validation :  9.1485\t\n",
      "[[225/1000]]\ttraining :  7.6074\t // validation :  9.1521\t\n",
      "[[226/1000]]\ttraining :  7.6069\t // validation :  9.1422\t\n",
      "[[227/1000]]\ttraining :  7.6064\t // validation :  9.1401\t\n",
      "[[228/1000]]\ttraining :  7.605\t // validation :  9.1413\t\n",
      "[[229/1000]]\ttraining :  7.6041\t // validation :  9.1394\t\n",
      "[[230/1000]]\ttraining :  7.6026\t // validation :  9.1377\t\n",
      "[[231/1000]]\ttraining :  7.6016\t // validation :  9.1375\t\n",
      "[[232/1000]]\ttraining :  7.6014\t // validation :  9.1366\t\n",
      "[[233/1000]]\ttraining :  7.6004\t // validation :  9.1365\t\n",
      "[[234/1000]]\ttraining :  7.5991\t // validation :  9.1365\t\n",
      "[[235/1000]]\ttraining :  7.5987\t // validation :  9.1336\t\n",
      "[[236/1000]]\ttraining :  7.5973\t // validation :  9.1296\t\n",
      "[[237/1000]]\ttraining :  7.5965\t // validation :  9.1307\t\n",
      "[[238/1000]]\ttraining :  7.596\t // validation :  9.131\t\n",
      "[[239/1000]]\ttraining :  7.5954\t // validation :  9.1286\t\n",
      "[[240/1000]]\ttraining :  7.5946\t // validation :  9.1205\t\n",
      "[[241/1000]]\ttraining :  7.5932\t // validation :  9.1177\t\n",
      "[[242/1000]]\ttraining :  7.5917\t // validation :  9.1263\t\n",
      "[[243/1000]]\ttraining :  7.5911\t // validation :  9.1248\t\n",
      "[[244/1000]]\ttraining :  7.5905\t // validation :  9.1202\t\n",
      "[[245/1000]]\ttraining :  7.5901\t // validation :  9.1127\t\n",
      "[[246/1000]]\ttraining :  7.5882\t // validation :  9.1214\t\n",
      "[[247/1000]]\ttraining :  7.5874\t // validation :  9.1294\t\n",
      "[[248/1000]]\ttraining :  7.5873\t // validation :  9.1272\t\n",
      "[[249/1000]]\ttraining :  7.5864\t // validation :  9.1284\t\n",
      "[[250/1000]]\ttraining :  7.5856\t // validation :  9.1261\t\n",
      "[[251/1000]]\ttraining :  7.5847\t // validation :  9.1284\t\n",
      "[[252/1000]]\ttraining :  7.5835\t // validation :  9.1249\t\n",
      "[[253/1000]]\ttraining :  7.583\t // validation :  9.1297\t\n",
      "[[254/1000]]\ttraining :  7.5819\t // validation :  9.125\t\n",
      "[[255/1000]]\ttraining :  7.5811\t // validation :  9.1297\t\n",
      "[[256/1000]]\ttraining :  7.5801\t // validation :  9.1207\t\n",
      "[[257/1000]]\ttraining :  7.579\t // validation :  9.1248\t\n",
      "[[258/1000]]\ttraining :  7.5782\t // validation :  9.1306\t\n",
      "[[259/1000]]\ttraining :  7.5782\t // validation :  9.1309\t\n",
      "[[260/1000]]\ttraining :  7.5772\t // validation :  9.1409\t\n",
      "[[261/1000]]\ttraining :  7.5764\t // validation :  9.1412\t\n",
      "[[262/1000]]\ttraining :  7.576\t // validation :  9.1479\t\n",
      "[[263/1000]]\ttraining :  7.5744\t // validation :  9.1465\t\n",
      "[[264/1000]]\ttraining :  7.5736\t // validation :  9.1454\t\n",
      "[[265/1000]]\ttraining :  7.5728\t // validation :  9.1432\t\n",
      "[[266/1000]]\ttraining :  7.5721\t // validation :  9.1407\t\n",
      "[[267/1000]]\ttraining :  7.5718\t // validation :  9.1404\t\n",
      "[[268/1000]]\ttraining :  7.5706\t // validation :  9.1425\t\n",
      "[[269/1000]]\ttraining :  7.5697\t // validation :  9.1444\t\n",
      "[[270/1000]]\ttraining :  7.568\t // validation :  9.1411\t\n",
      "[[271/1000]]\ttraining :  7.5674\t // validation :  9.1376\t\n",
      "[[272/1000]]\ttraining :  7.5669\t // validation :  9.1367\t\n",
      "[[273/1000]]\ttraining :  7.5661\t // validation :  9.1377\t\n",
      "[[274/1000]]\ttraining :  7.5656\t // validation :  9.1587\t\n",
      "[[275/1000]]\ttraining :  7.5651\t // validation :  9.1617\t\n",
      "[[276/1000]]\ttraining :  7.5642\t // validation :  9.1467\t\n",
      "[[277/1000]]\ttraining :  7.5635\t // validation :  9.1515\t\n",
      "[[278/1000]]\ttraining :  7.5626\t // validation :  9.1614\t\n",
      "[[279/1000]]\ttraining :  7.5614\t // validation :  9.1737\t\n",
      "[[280/1000]]\ttraining :  7.561\t // validation :  9.1751\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[281/1000]]\ttraining :  7.5601\t // validation :  9.1745\t\n",
      "[[282/1000]]\ttraining :  7.5596\t // validation :  9.1661\t\n",
      "[[283/1000]]\ttraining :  7.5585\t // validation :  9.1611\t\n",
      "[[284/1000]]\ttraining :  7.5581\t // validation :  9.1504\t\n",
      "[[285/1000]]\ttraining :  7.5579\t // validation :  9.1561\t\n",
      "[[286/1000]]\ttraining :  7.5569\t // validation :  9.1571\t\n",
      "[[287/1000]]\ttraining :  7.5556\t // validation :  9.163\t\n",
      "[[288/1000]]\ttraining :  7.5549\t // validation :  9.1609\t\n",
      "[[289/1000]]\ttraining :  7.554\t // validation :  9.1566\t\n",
      "[[290/1000]]\ttraining :  7.5533\t // validation :  9.1721\t\n",
      "[[291/1000]]\ttraining :  7.5526\t // validation :  9.1674\t\n",
      "[[292/1000]]\ttraining :  7.5513\t // validation :  9.1664\t\n",
      "[[293/1000]]\ttraining :  7.5507\t // validation :  9.1761\t\n",
      "[[294/1000]]\ttraining :  7.5499\t // validation :  9.1832\t\n",
      "[[295/1000]]\ttraining :  7.5489\t // validation :  9.187\t\n",
      "[[296/1000]]\ttraining :  7.5483\t // validation :  9.1858\t\n",
      "[[297/1000]]\ttraining :  7.5479\t // validation :  9.1842\t\n",
      "[[298/1000]]\ttraining :  7.5476\t // validation :  9.1775\t\n",
      "[[299/1000]]\ttraining :  7.5467\t // validation :  9.1801\t\n",
      "[[300/1000]]\ttraining :  7.5462\t // validation :  9.175\t\n",
      "[[301/1000]]\ttraining :  7.5458\t // validation :  9.1862\t\n",
      "[[302/1000]]\ttraining :  7.5446\t // validation :  9.179\t\n",
      "[[303/1000]]\ttraining :  7.543\t // validation :  9.1879\t\n",
      "[[304/1000]]\ttraining :  7.5421\t // validation :  9.1882\t\n",
      "[[305/1000]]\ttraining :  7.5412\t // validation :  9.1938\t\n",
      "[[306/1000]]\ttraining :  7.5407\t // validation :  9.1959\t\n",
      "[[307/1000]]\ttraining :  7.5403\t // validation :  9.1988\t\n",
      "[[308/1000]]\ttraining :  7.5393\t // validation :  9.1983\t\n",
      "[[309/1000]]\ttraining :  7.5388\t // validation :  9.1924\t\n",
      "[[310/1000]]\ttraining :  7.5384\t // validation :  9.1971\t\n",
      "[[311/1000]]\ttraining :  7.5376\t // validation :  9.1964\t\n",
      "[[312/1000]]\ttraining :  7.5368\t // validation :  9.2046\t\n",
      "[[313/1000]]\ttraining :  7.5368\t // validation :  9.2156\t\n",
      "[[314/1000]]\ttraining :  7.5355\t // validation :  9.2226\t\n",
      "[[315/1000]]\ttraining :  7.5351\t // validation :  9.233\t\n",
      "[[316/1000]]\ttraining :  7.5343\t // validation :  9.2342\t\n",
      "[[317/1000]]\ttraining :  7.533\t // validation :  9.2237\t\n",
      "[[318/1000]]\ttraining :  7.532\t // validation :  9.2122\t\n",
      "[[319/1000]]\ttraining :  7.5313\t // validation :  9.2116\t\n",
      "[[320/1000]]\ttraining :  7.5298\t // validation :  9.2159\t\n",
      "[[321/1000]]\ttraining :  7.5298\t // validation :  9.2131\t\n",
      "[[322/1000]]\ttraining :  7.5286\t // validation :  9.2246\t\n",
      "[[323/1000]]\ttraining :  7.5274\t // validation :  9.2306\t\n",
      "[[324/1000]]\ttraining :  7.5268\t // validation :  9.2405\t\n",
      "[[325/1000]]\ttraining :  7.5263\t // validation :  9.2461\t\n",
      "[[326/1000]]\ttraining :  7.5259\t // validation :  9.2577\t\n",
      "[[327/1000]]\ttraining :  7.5247\t // validation :  9.251\t\n",
      "[[328/1000]]\ttraining :  7.5239\t // validation :  9.2359\t\n",
      "[[329/1000]]\ttraining :  7.5238\t // validation :  9.226\t\n",
      "[[330/1000]]\ttraining :  7.5228\t // validation :  9.2257\t\n",
      "[[331/1000]]\ttraining :  7.5221\t // validation :  9.2271\t\n",
      "[[332/1000]]\ttraining :  7.5215\t // validation :  9.2322\t\n",
      "[[333/1000]]\ttraining :  7.521\t // validation :  9.2308\t\n",
      "[[334/1000]]\ttraining :  7.5201\t // validation :  9.2457\t\n",
      "[[335/1000]]\ttraining :  7.5193\t // validation :  9.2473\t\n",
      "[[336/1000]]\ttraining :  7.519\t // validation :  9.2552\t\n",
      "[[337/1000]]\ttraining :  7.5184\t // validation :  9.263\t\n",
      "[[338/1000]]\ttraining :  7.5176\t // validation :  9.2571\t\n",
      "[[339/1000]]\ttraining :  7.5167\t // validation :  9.2564\t\n",
      "[[340/1000]]\ttraining :  7.5162\t // validation :  9.2576\t\n",
      "[[341/1000]]\ttraining :  7.5153\t // validation :  9.2472\t\n",
      "[[342/1000]]\ttraining :  7.5158\t // validation :  9.254\t\n",
      "[[343/1000]]\ttraining :  7.5151\t // validation :  9.2478\t\n",
      "[[344/1000]]\ttraining :  7.5142\t // validation :  9.2554\t\n",
      "[[345/1000]]\ttraining :  7.5133\t // validation :  9.2506\t\n",
      "[[346/1000]]\ttraining :  7.5134\t // validation :  9.2425\t\n",
      "[[347/1000]]\ttraining :  7.5125\t // validation :  9.2555\t\n",
      "[[348/1000]]\ttraining :  7.5111\t // validation :  9.255\t\n",
      "[[349/1000]]\ttraining :  7.5105\t // validation :  9.2637\t\n",
      "[[350/1000]]\ttraining :  7.5099\t // validation :  9.2742\t\n",
      "[[351/1000]]\ttraining :  7.5101\t // validation :  9.2687\t\n",
      "[[352/1000]]\ttraining :  7.5094\t // validation :  9.2802\t\n",
      "[[353/1000]]\ttraining :  7.5088\t // validation :  9.2774\t\n",
      "[[354/1000]]\ttraining :  7.5077\t // validation :  9.2781\t\n",
      "[[355/1000]]\ttraining :  7.5069\t // validation :  9.2833\t\n",
      "[[356/1000]]\ttraining :  7.5062\t // validation :  9.2817\t\n",
      "[[357/1000]]\ttraining :  7.506\t // validation :  9.2799\t\n",
      "[[358/1000]]\ttraining :  7.5048\t // validation :  9.2921\t\n",
      "[[359/1000]]\ttraining :  7.5036\t // validation :  9.3046\t\n",
      "[[360/1000]]\ttraining :  7.5033\t // validation :  9.2902\t\n",
      "[[361/1000]]\ttraining :  7.5021\t // validation :  9.2889\t\n",
      "[[362/1000]]\ttraining :  7.5016\t // validation :  9.2889\t\n",
      "[[363/1000]]\ttraining :  7.5013\t // validation :  9.2814\t\n",
      "[[364/1000]]\ttraining :  7.5005\t // validation :  9.2942\t\n",
      "[[365/1000]]\ttraining :  7.4991\t // validation :  9.3057\t\n",
      "[[366/1000]]\ttraining :  7.4985\t // validation :  9.315\t\n",
      "[[367/1000]]\ttraining :  7.4985\t // validation :  9.3154\t\n",
      "[[368/1000]]\ttraining :  7.4976\t // validation :  9.3146\t\n",
      "[[369/1000]]\ttraining :  7.4968\t // validation :  9.3078\t\n",
      "[[370/1000]]\ttraining :  7.4957\t // validation :  9.3151\t\n",
      "[[371/1000]]\ttraining :  7.4952\t // validation :  9.3075\t\n",
      "[[372/1000]]\ttraining :  7.4947\t // validation :  9.3108\t\n",
      "[[373/1000]]\ttraining :  7.4938\t // validation :  9.3047\t\n",
      "[[374/1000]]\ttraining :  7.4929\t // validation :  9.3044\t\n",
      "[[375/1000]]\ttraining :  7.4924\t // validation :  9.2964\t\n",
      "[[376/1000]]\ttraining :  7.4918\t // validation :  9.3073\t\n",
      "[[377/1000]]\ttraining :  7.4913\t // validation :  9.31\t\n",
      "[[378/1000]]\ttraining :  7.4902\t // validation :  9.3093\t\n",
      "[[379/1000]]\ttraining :  7.4896\t // validation :  9.3091\t\n",
      "[[380/1000]]\ttraining :  7.4889\t // validation :  9.3125\t\n",
      "[[381/1000]]\ttraining :  7.4877\t // validation :  9.3156\t\n",
      "[[382/1000]]\ttraining :  7.4869\t // validation :  9.2999\t\n",
      "[[383/1000]]\ttraining :  7.4859\t // validation :  9.2889\t\n",
      "[[384/1000]]\ttraining :  7.4852\t // validation :  9.2788\t\n",
      "[[385/1000]]\ttraining :  7.4844\t // validation :  9.2763\t\n",
      "[[386/1000]]\ttraining :  7.4834\t // validation :  9.2793\t\n",
      "[[387/1000]]\ttraining :  7.4833\t // validation :  9.2792\t\n",
      "[[388/1000]]\ttraining :  7.4823\t // validation :  9.2734\t\n",
      "[[389/1000]]\ttraining :  7.4819\t // validation :  9.271\t\n",
      "[[390/1000]]\ttraining :  7.4811\t // validation :  9.2622\t\n",
      "[[391/1000]]\ttraining :  7.4801\t // validation :  9.2714\t\n",
      "[[392/1000]]\ttraining :  7.4794\t // validation :  9.2652\t\n",
      "[[393/1000]]\ttraining :  7.4789\t // validation :  9.2744\t\n",
      "[[394/1000]]\ttraining :  7.4786\t // validation :  9.2751\t\n",
      "[[395/1000]]\ttraining :  7.4783\t // validation :  9.2797\t\n",
      "[[396/1000]]\ttraining :  7.4775\t // validation :  9.2725\t\n",
      "[[397/1000]]\ttraining :  7.4761\t // validation :  9.2702\t\n",
      "[[398/1000]]\ttraining :  7.4753\t // validation :  9.2614\t\n",
      "[[399/1000]]\ttraining :  7.4749\t // validation :  9.2674\t\n",
      "[[400/1000]]\ttraining :  7.4743\t // validation :  9.2592\t\n",
      "[[401/1000]]\ttraining :  7.4731\t // validation :  9.2546\t\n",
      "[[402/1000]]\ttraining :  7.4725\t // validation :  9.2555\t\n",
      "[[403/1000]]\ttraining :  7.4722\t // validation :  9.2557\t\n",
      "[[404/1000]]\ttraining :  7.4717\t // validation :  9.2567\t\n",
      "[[405/1000]]\ttraining :  7.4706\t // validation :  9.259\t\n",
      "[[406/1000]]\ttraining :  7.4707\t // validation :  9.2533\t\n",
      "[[407/1000]]\ttraining :  7.4694\t // validation :  9.2508\t\n",
      "[[408/1000]]\ttraining :  7.4688\t // validation :  9.2579\t\n",
      "[[409/1000]]\ttraining :  7.4684\t // validation :  9.2575\t\n",
      "[[410/1000]]\ttraining :  7.4677\t // validation :  9.2593\t\n",
      "[[411/1000]]\ttraining :  7.467\t // validation :  9.2586\t\n",
      "[[412/1000]]\ttraining :  7.466\t // validation :  9.2639\t\n",
      "[[413/1000]]\ttraining :  7.4659\t // validation :  9.2553\t\n",
      "[[414/1000]]\ttraining :  7.4652\t // validation :  9.2474\t\n",
      "[[415/1000]]\ttraining :  7.4641\t // validation :  9.2456\t\n",
      "[[416/1000]]\ttraining :  7.463\t // validation :  9.2405\t\n",
      "[[417/1000]]\ttraining :  7.4627\t // validation :  9.2409\t\n",
      "[[418/1000]]\ttraining :  7.4622\t // validation :  9.2433\t\n",
      "[[419/1000]]\ttraining :  7.4614\t // validation :  9.2475\t\n",
      "[[420/1000]]\ttraining :  7.4613\t // validation :  9.2452\t\n",
      "[[421/1000]]\ttraining :  7.4608\t // validation :  9.2457\t\n",
      "[[422/1000]]\ttraining :  7.4606\t // validation :  9.2455\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[423/1000]]\ttraining :  7.4594\t // validation :  9.2461\t\n",
      "[[424/1000]]\ttraining :  7.4586\t // validation :  9.2483\t\n",
      "[[425/1000]]\ttraining :  7.4577\t // validation :  9.2484\t\n",
      "[[426/1000]]\ttraining :  7.4567\t // validation :  9.2501\t\n",
      "[[427/1000]]\ttraining :  7.4559\t // validation :  9.2462\t\n",
      "[[428/1000]]\ttraining :  7.4548\t // validation :  9.2444\t\n",
      "[[429/1000]]\ttraining :  7.4543\t // validation :  9.244\t\n",
      "[[430/1000]]\ttraining :  7.4538\t // validation :  9.2418\t\n",
      "[[431/1000]]\ttraining :  7.4529\t // validation :  9.2374\t\n",
      "[[432/1000]]\ttraining :  7.4527\t // validation :  9.2436\t\n",
      "[[433/1000]]\ttraining :  7.4517\t // validation :  9.2379\t\n",
      "[[434/1000]]\ttraining :  7.4513\t // validation :  9.2421\t\n",
      "[[435/1000]]\ttraining :  7.4507\t // validation :  9.2468\t\n",
      "[[436/1000]]\ttraining :  7.4504\t // validation :  9.251\t\n",
      "[[437/1000]]\ttraining :  7.4494\t // validation :  9.2534\t\n",
      "[[438/1000]]\ttraining :  7.4489\t // validation :  9.2601\t\n",
      "[[439/1000]]\ttraining :  7.4485\t // validation :  9.2636\t\n",
      "[[440/1000]]\ttraining :  7.4481\t // validation :  9.2567\t\n",
      "[[441/1000]]\ttraining :  7.4471\t // validation :  9.2541\t\n",
      "[[442/1000]]\ttraining :  7.4462\t // validation :  9.2533\t\n",
      "[[443/1000]]\ttraining :  7.4455\t // validation :  9.2533\t\n",
      "[[444/1000]]\ttraining :  7.4447\t // validation :  9.2596\t\n",
      "[[445/1000]]\ttraining :  7.4437\t // validation :  9.2561\t\n",
      "[[446/1000]]\ttraining :  7.4427\t // validation :  9.2611\t\n",
      "[[447/1000]]\ttraining :  7.4424\t // validation :  9.2635\t\n",
      "[[448/1000]]\ttraining :  7.4419\t // validation :  9.2705\t\n",
      "[[449/1000]]\ttraining :  7.4414\t // validation :  9.2647\t\n",
      "[[450/1000]]\ttraining :  7.4407\t // validation :  9.2645\t\n",
      "[[451/1000]]\ttraining :  7.4407\t // validation :  9.2631\t\n",
      "[[452/1000]]\ttraining :  7.4408\t // validation :  9.2622\t\n",
      "[[453/1000]]\ttraining :  7.4406\t // validation :  9.2617\t\n",
      "[[454/1000]]\ttraining :  7.4395\t // validation :  9.2678\t\n",
      "[[455/1000]]\ttraining :  7.4388\t // validation :  9.2726\t\n",
      "[[456/1000]]\ttraining :  7.4377\t // validation :  9.2819\t\n",
      "[[457/1000]]\ttraining :  7.4374\t // validation :  9.2886\t\n",
      "[[458/1000]]\ttraining :  7.436\t // validation :  9.2942\t\n",
      "[[459/1000]]\ttraining :  7.4352\t // validation :  9.3014\t\n",
      "[[460/1000]]\ttraining :  7.4344\t // validation :  9.3033\t\n",
      "[[461/1000]]\ttraining :  7.4338\t // validation :  9.3029\t\n",
      "[[462/1000]]\ttraining :  7.4334\t // validation :  9.301\t\n",
      "[[463/1000]]\ttraining :  7.4331\t // validation :  9.3003\t\n",
      "[[464/1000]]\ttraining :  7.4327\t // validation :  9.2974\t\n",
      "[[465/1000]]\ttraining :  7.4323\t // validation :  9.303\t\n",
      "[[466/1000]]\ttraining :  7.4319\t // validation :  9.3118\t\n",
      "[[467/1000]]\ttraining :  7.4309\t // validation :  9.319\t\n",
      "[[468/1000]]\ttraining :  7.4303\t // validation :  9.3174\t\n",
      "[[469/1000]]\ttraining :  7.4294\t // validation :  9.3256\t\n",
      "[[470/1000]]\ttraining :  7.4283\t // validation :  9.3299\t\n",
      "[[471/1000]]\ttraining :  7.4275\t // validation :  9.3394\t\n",
      "[[472/1000]]\ttraining :  7.4269\t // validation :  9.3423\t\n",
      "[[473/1000]]\ttraining :  7.4263\t // validation :  9.3451\t\n",
      "[[474/1000]]\ttraining :  7.426\t // validation :  9.3431\t\n",
      "[[475/1000]]\ttraining :  7.4257\t // validation :  9.347\t\n",
      "[[476/1000]]\ttraining :  7.4244\t // validation :  9.3533\t\n",
      "[[477/1000]]\ttraining :  7.4239\t // validation :  9.3544\t\n",
      "[[478/1000]]\ttraining :  7.4232\t // validation :  9.361\t\n",
      "[[479/1000]]\ttraining :  7.4224\t // validation :  9.3709\t\n",
      "[[480/1000]]\ttraining :  7.4221\t // validation :  9.377\t\n",
      "[[481/1000]]\ttraining :  7.422\t // validation :  9.3817\t\n",
      "[[482/1000]]\ttraining :  7.4218\t // validation :  9.3776\t\n",
      "[[483/1000]]\ttraining :  7.4207\t // validation :  9.3786\t\n",
      "[[484/1000]]\ttraining :  7.4202\t // validation :  9.3787\t\n",
      "[[485/1000]]\ttraining :  7.4193\t // validation :  9.3897\t\n",
      "[[486/1000]]\ttraining :  7.4185\t // validation :  9.3922\t\n",
      "[[487/1000]]\ttraining :  7.4184\t // validation :  9.3944\t\n",
      "[[488/1000]]\ttraining :  7.4178\t // validation :  9.4006\t\n",
      "[[489/1000]]\ttraining :  7.4167\t // validation :  9.3989\t\n",
      "[[490/1000]]\ttraining :  7.4165\t // validation :  9.3987\t\n",
      "[[491/1000]]\ttraining :  7.4159\t // validation :  9.4059\t\n",
      "[[492/1000]]\ttraining :  7.4152\t // validation :  9.4186\t\n",
      "[[493/1000]]\ttraining :  7.4149\t // validation :  9.4272\t\n",
      "[[494/1000]]\ttraining :  7.4149\t // validation :  9.4298\t\n",
      "[[495/1000]]\ttraining :  7.4143\t // validation :  9.4288\t\n",
      "[[496/1000]]\ttraining :  7.4136\t // validation :  9.4338\t\n",
      "[[497/1000]]\ttraining :  7.4133\t // validation :  9.4407\t\n",
      "[[498/1000]]\ttraining :  7.413\t // validation :  9.4457\t\n",
      "[[499/1000]]\ttraining :  7.4112\t // validation :  9.4532\t\n",
      "[[500/1000]]\ttraining :  7.411\t // validation :  9.4547\t\n",
      "[[501/1000]]\ttraining :  7.4099\t // validation :  9.4597\t\n",
      "[[502/1000]]\ttraining :  7.4099\t // validation :  9.4681\t\n",
      "[[503/1000]]\ttraining :  7.4095\t // validation :  9.4681\t\n",
      "[[504/1000]]\ttraining :  7.4083\t // validation :  9.4728\t\n",
      "[[505/1000]]\ttraining :  7.4075\t // validation :  9.4831\t\n",
      "[[506/1000]]\ttraining :  7.4064\t // validation :  9.4952\t\n",
      "[[507/1000]]\ttraining :  7.4068\t // validation :  9.5005\t\n",
      "[[508/1000]]\ttraining :  7.4058\t // validation :  9.5078\t\n",
      "[[509/1000]]\ttraining :  7.4057\t // validation :  9.515\t\n",
      "[[510/1000]]\ttraining :  7.4053\t // validation :  9.5232\t\n",
      "[[511/1000]]\ttraining :  7.4053\t // validation :  9.5233\t\n",
      "[[512/1000]]\ttraining :  7.4048\t // validation :  9.5194\t\n",
      "[[513/1000]]\ttraining :  7.4031\t // validation :  9.5323\t\n",
      "[[514/1000]]\ttraining :  7.4027\t // validation :  9.5424\t\n",
      "[[515/1000]]\ttraining :  7.4018\t // validation :  9.5544\t\n",
      "[[516/1000]]\ttraining :  7.4023\t // validation :  9.5372\t\n",
      "[[517/1000]]\ttraining :  7.4011\t // validation :  9.5451\t\n",
      "[[518/1000]]\ttraining :  7.4014\t // validation :  9.5503\t\n",
      "[[519/1000]]\ttraining :  7.4004\t // validation :  9.5615\t\n",
      "[[520/1000]]\ttraining :  7.3995\t // validation :  9.5608\t\n",
      "[[521/1000]]\ttraining :  7.3996\t // validation :  9.5705\t\n",
      "[[522/1000]]\ttraining :  7.3991\t // validation :  9.5886\t\n",
      "[[523/1000]]\ttraining :  7.3991\t // validation :  9.5921\t\n",
      "[[524/1000]]\ttraining :  7.3987\t // validation :  9.6015\t\n",
      "[[525/1000]]\ttraining :  7.3977\t // validation :  9.6138\t\n",
      "[[526/1000]]\ttraining :  7.3974\t // validation :  9.617\t\n",
      "[[527/1000]]\ttraining :  7.3961\t // validation :  9.6285\t\n",
      "[[528/1000]]\ttraining :  7.3957\t // validation :  9.635\t\n",
      "[[529/1000]]\ttraining :  7.395\t // validation :  9.6449\t\n",
      "[[530/1000]]\ttraining :  7.3947\t // validation :  9.6605\t\n",
      "[[531/1000]]\ttraining :  7.3947\t // validation :  9.6872\t\n",
      "[[532/1000]]\ttraining :  7.3935\t // validation :  9.6949\t\n",
      "[[533/1000]]\ttraining :  7.3929\t // validation :  9.7091\t\n",
      "[[534/1000]]\ttraining :  7.392\t // validation :  9.6975\t\n",
      "[[535/1000]]\ttraining :  7.3916\t // validation :  9.7\t\n",
      "[[536/1000]]\ttraining :  7.3917\t // validation :  9.7151\t\n",
      "[[537/1000]]\ttraining :  7.3909\t // validation :  9.7437\t\n",
      "[[538/1000]]\ttraining :  7.3908\t // validation :  9.7523\t\n",
      "[[539/1000]]\ttraining :  7.3899\t // validation :  9.7607\t\n",
      "[[540/1000]]\ttraining :  7.3901\t // validation :  9.7723\t\n",
      "[[541/1000]]\ttraining :  7.3893\t // validation :  9.7712\t\n",
      "[[542/1000]]\ttraining :  7.389\t // validation :  9.7821\t\n",
      "[[543/1000]]\ttraining :  7.3875\t // validation :  9.8158\t\n",
      "[[544/1000]]\ttraining :  7.3877\t // validation :  9.8362\t\n",
      "[[545/1000]]\ttraining :  7.3867\t // validation :  9.87\t\n",
      "[[546/1000]]\ttraining :  7.386\t // validation :  9.8948\t\n",
      "[[547/1000]]\ttraining :  7.3864\t // validation :  9.9299\t\n",
      "[[548/1000]]\ttraining :  7.3854\t // validation :  9.913\t\n",
      "[[549/1000]]\ttraining :  7.3855\t // validation :  9.9352\t\n",
      "[[550/1000]]\ttraining :  7.3847\t // validation :  9.9417\t\n",
      "[[551/1000]]\ttraining :  7.3852\t // validation :  9.9924\t\n",
      "[[552/1000]]\ttraining :  7.3845\t // validation :  10.0481\t\n",
      "[[553/1000]]\ttraining :  7.3838\t // validation :  10.1094\t\n",
      "[[554/1000]]\ttraining :  7.3834\t // validation :  10.0951\t\n",
      "[[555/1000]]\ttraining :  7.3827\t // validation :  10.1128\t\n",
      "[[556/1000]]\ttraining :  7.3819\t // validation :  10.1468\t\n",
      "[[557/1000]]\ttraining :  7.3821\t // validation :  10.1931\t\n",
      "[[558/1000]]\ttraining :  7.3808\t // validation :  10.2773\t\n",
      "[[559/1000]]\ttraining :  7.3797\t // validation :  10.2762\t\n",
      "[[560/1000]]\ttraining :  7.3792\t // validation :  10.2759\t\n",
      "[[561/1000]]\ttraining :  7.3782\t // validation :  10.2053\t\n",
      "[[562/1000]]\ttraining :  7.3774\t // validation :  10.2444\t\n",
      "[[563/1000]]\ttraining :  7.3766\t // validation :  10.2835\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[564/1000]]\ttraining :  7.3767\t // validation :  10.2917\t\n",
      "[[565/1000]]\ttraining :  7.3764\t // validation :  10.3282\t\n",
      "[[566/1000]]\ttraining :  7.3764\t // validation :  10.4292\t\n",
      "[[567/1000]]\ttraining :  7.3754\t // validation :  10.519\t\n",
      "[[568/1000]]\ttraining :  7.3753\t // validation :  10.6299\t\n",
      "[[569/1000]]\ttraining :  7.3758\t // validation :  10.6887\t\n",
      "[[570/1000]]\ttraining :  7.3754\t // validation :  10.7279\t\n",
      "[[571/1000]]\ttraining :  7.3749\t // validation :  11.0006\t\n",
      "[[572/1000]]\ttraining :  7.3737\t // validation :  10.866\t\n",
      "[[573/1000]]\ttraining :  7.3731\t // validation :  10.9614\t\n",
      "[[574/1000]]\ttraining :  7.3722\t // validation :  10.9858\t\n",
      "[[575/1000]]\ttraining :  7.3718\t // validation :  11.0027\t\n",
      "[[576/1000]]\ttraining :  7.371\t // validation :  11.1966\t\n",
      "[[577/1000]]\ttraining :  7.3704\t // validation :  11.3023\t\n",
      "[[578/1000]]\ttraining :  7.3708\t // validation :  12.1426\t\n",
      "[[579/1000]]\ttraining :  7.3707\t // validation :  12.143\t\n",
      "[[580/1000]]\ttraining :  7.3702\t // validation :  11.9479\t\n",
      "[[581/1000]]\ttraining :  7.3696\t // validation :  12.3019\t\n",
      "[[582/1000]]\ttraining :  7.3689\t // validation :  12.6656\t\n",
      "[[583/1000]]\ttraining :  7.3682\t // validation :  12.9946\t\n",
      "[[584/1000]]\ttraining :  7.3678\t // validation :  13.0664\t\n",
      "[[585/1000]]\ttraining :  7.367\t // validation :  13.1525\t\n",
      "[[586/1000]]\ttraining :  7.3663\t // validation :  13.2366\t\n",
      "[[587/1000]]\ttraining :  7.3656\t // validation :  12.8655\t\n",
      "[[588/1000]]\ttraining :  7.3653\t // validation :  13.1414\t\n",
      "[[589/1000]]\ttraining :  7.3645\t // validation :  13.22\t\n",
      "[[590/1000]]\ttraining :  7.3646\t // validation :  13.4038\t\n",
      "[[591/1000]]\ttraining :  7.3639\t // validation :  13.6864\t\n",
      "[[592/1000]]\ttraining :  7.3633\t // validation :  13.9543\t\n",
      "[[593/1000]]\ttraining :  7.3634\t // validation :  14.0295\t\n",
      "[[594/1000]]\ttraining :  7.363\t // validation :  14.1128\t\n",
      "[[595/1000]]\ttraining :  7.3626\t // validation :  14.1191\t\n",
      "[[596/1000]]\ttraining :  7.3628\t // validation :  14.2975\t\n",
      "[[597/1000]]\ttraining :  7.3615\t // validation :  14.351\t\n",
      "[[598/1000]]\ttraining :  7.361\t // validation :  14.3075\t\n",
      "[[599/1000]]\ttraining :  7.3604\t // validation :  14.3275\t\n",
      "[[600/1000]]\ttraining :  7.3594\t // validation :  14.4268\t\n",
      "[[601/1000]]\ttraining :  7.3595\t // validation :  14.4714\t\n",
      "[[602/1000]]\ttraining :  7.3594\t // validation :  14.5634\t\n",
      "[[603/1000]]\ttraining :  7.36\t // validation :  14.6245\t\n",
      "[[604/1000]]\ttraining :  7.3593\t // validation :  14.6851\t\n",
      "[[605/1000]]\ttraining :  7.3589\t // validation :  14.7175\t\n",
      "[[606/1000]]\ttraining :  7.3586\t // validation :  14.7592\t\n",
      "[[607/1000]]\ttraining :  7.3577\t // validation :  14.8108\t\n",
      "[[608/1000]]\ttraining :  7.3576\t // validation :  14.8286\t\n",
      "[[609/1000]]\ttraining :  7.3568\t // validation :  14.8227\t\n",
      "[[610/1000]]\ttraining :  7.3567\t // validation :  14.872\t\n",
      "[[611/1000]]\ttraining :  7.3554\t // validation :  14.932\t\n",
      "[[612/1000]]\ttraining :  7.3556\t // validation :  14.9499\t\n",
      "[[613/1000]]\ttraining :  7.3555\t // validation :  15.0571\t\n",
      "[[614/1000]]\ttraining :  7.3546\t // validation :  15.1178\t\n",
      "[[615/1000]]\ttraining :  7.3539\t // validation :  15.1604\t\n",
      "[[616/1000]]\ttraining :  7.3535\t"
     ]
    }
   ],
   "source": [
    "minLoss=999\n",
    "max_grad_norm=5\n",
    "\n",
    "best_realV,best_predV=[],[]\n",
    "best_epoch=0\n",
    "\n",
    "train_loss=[]\n",
    "valid_loss=[]\n",
    "\n",
    "bestMAE=[999,0]\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    model.train()\n",
    "    lossSum =0\n",
    "    lossCnt =0\n",
    "    for i in range(0,len(train_x),batch_size):\n",
    "        if i+batch_size > len(train_x): break\n",
    "        else:\n",
    "            x = torch.tensor(train_x[i:i+batch_size])\n",
    "            y = torch.tensor(train_y[i:i+batch_size])\n",
    "            m = train_mask[i:i+batch_size]\n",
    "         \n",
    "            x = Variable(x)\n",
    "            y = Variable(y)\n",
    "\n",
    "            if is_cuda: x=x.cuda(); y=y.cuda()\n",
    "            optimizer.zero_grad() # Clears existing gradients from previous epoch\n",
    "            output, hidden = model(x.float())\n",
    "            \n",
    "            output.type(dtype)\n",
    "            \n",
    "            loss = criterion(output, y.view(-1).float())    #train       \n",
    "            loss.backward(retain_graph=True) # Does backpropagation and calculates gradients\n",
    "            torch_utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "            optimizer.step() # Updates the weights accordingly    \n",
    "            lossSum += loss.item()\n",
    "            lossCnt += 1\n",
    "\n",
    "    train_loss.append(lossSum/lossCnt)     \n",
    "    print('[[{}/{}]]\\ttraining : '.format(epoch,n_epochs),round(lossSum/lossCnt,4), end='\\t')\n",
    "    \n",
    "    model.eval()\n",
    "    lossSum =0\n",
    "    lossCnt =0\n",
    "    realV=[]\n",
    "    predV=[]\n",
    "    for i in range(0,len(valid_x),batch_size):\n",
    "        if i+batch_size > len(valid_x): break\n",
    "        else:\n",
    "            x = torch.tensor(valid_x[i:i+batch_size])\n",
    "            y = torch.tensor(valid_y[i:i+batch_size])\n",
    "            m = test_mask[i:i+batch_size]\n",
    "                \n",
    "            x = Variable(x)\n",
    "            y = Variable(y)\n",
    "\n",
    "            if is_cuda: x=x.cuda(); y=y.cuda()\n",
    "            output, hidden = model(x.float())   \n",
    "            loss = criterion(output, y.view(-1).float())    #train   \n",
    "            \n",
    "            realV+=y.view(-1).tolist()\n",
    "            predV+=output.view(-1).tolist()\n",
    "           \n",
    "            lossSum += loss.item()\n",
    "            lossCnt += 1\n",
    "    \n",
    "    \n",
    "\n",
    "    if bestMAE[0]>lossSum/lossCnt:\n",
    "        bestMAE[0]=lossSum/lossCnt\n",
    "        bestMAE[1]=epoch\n",
    "        \n",
    "    print(' // validation : ',round(lossSum/lossCnt,4), end='\\t')    \n",
    "    valid_loss.append(lossSum/lossCnt)\n",
    "    \n",
    "    if minLoss>(lossSum/lossCnt):\n",
    "        print('****',str(epoch),'****')\n",
    "        torch.save(model.state_dict(), savePath+modelName+fName+'_'+modelVer+\".pth\")\n",
    "        best_realV=realV\n",
    "        best_predV=predV\n",
    "        best_epoch=epoch\n",
    "        minLoss=lossSum/lossCnt\n",
    "    else:\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 결과 검증 그래프\n",
    "print(fName)\n",
    "print('learning Rate : ',lr)\n",
    "print('layer : ',num_layers)\n",
    "print(bestMAE)\n",
    "\n",
    "print('hidden_dim : ',hidden_dim)\n",
    "plt.scatter(best_realV, best_predV,s=0.3)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 반복학습에 따른 오차 선그래프\n",
    "plt.plot(train_loss)\n",
    "plt.plot(valid_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(savePath+modelName+fName+'_'+modelVer+\".pth\"))\n",
    "\n",
    "minLoss=999\n",
    "model.eval()\n",
    "lossSum, lossCnt = 0, 0\n",
    "realV, predV, maskV, caseV=[],[],[],[]\n",
    "\n",
    "for i in range(0,len(test_x),batch_size):\n",
    "    if i+batch_size > len(test_x): break\n",
    "    else:\n",
    "        x = torch.tensor(test_x[i:i+batch_size])\n",
    "        y = torch.tensor(test_y[i:i+batch_size])\n",
    "        m = test_mask[i:i+batch_size]\n",
    "        cid = test_case[i:i+batch_size]\n",
    "                \n",
    "        x = Variable(x)\n",
    "        y = Variable(y)\n",
    "\n",
    "        if is_cuda: x=x.cuda(); y=y.cuda()\n",
    "        output, hidden = model(x.float())   \n",
    "        loss = criterion(output, y.view(-1).float())    #train   \n",
    "            \n",
    "        realV+=y.view(-1).tolist()\n",
    "        predV+=output.view(-1).tolist()\n",
    "        maskV+=m\n",
    "        caseV+=cid\n",
    "           \n",
    "        lossSum += loss.item()\n",
    "        lossCnt += 1\n",
    "        \n",
    "print('test : ',round(lossSum/lossCnt,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fName)\n",
    "print('learning Rate : ',lr)\n",
    "print('layer : ',num_layers)\n",
    "print(bestMAE[0])\n",
    "print('hidden_dim : ',hidden_dim)\n",
    "\n",
    "plt.scatter(realV, predV,s=0.3)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefixResult=[0]*maxTraceLen\n",
    "prefixCount=[0]*maxTraceLen\n",
    "for rv,pv,mv in zip(realV,predV,maskV):\n",
    "    if mv>=maxTraceLen:\n",
    "        prefixResult[maxTraceLen-1]+=abs(rv-pv)\n",
    "        prefixCount[maxTraceLen-1]+=1\n",
    "    else:\n",
    "        prefixResult[mv]+=abs(rv-pv)\n",
    "        prefixCount[mv]+=1\n",
    "totalMae=sum(prefixResult)/sum(prefixCount)\n",
    "print('totalMAE : ',totalMae,' cnt : ',sum(prefixCount))\n",
    "    \n",
    "for i in range(maxTraceLen):\n",
    "    if prefixCount[i]==0:\n",
    "        print(str(i), '\\t : ' ,prefixResult[i])\n",
    "    else:     \n",
    "        print(str(i), '\\t : ' ,prefixResult[i]/prefixCount[i],' cnt : ',prefixCount[i])\n",
    "        prefixResult[i]=prefixResult[i]/prefixCount[i]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
